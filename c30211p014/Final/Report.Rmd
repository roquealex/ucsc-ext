---
title: "Wind Analysis Of Northern Yucatan Coast for Kiteboarding"
author: "Roque Arcudia, Arshia Razavi, Eda Uysal"
date: "August 21, 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Motivation

Kiteboarding is an adventure water sport that consists of using a large steerable kite to pull yourself around on a board on top of the water. The kites are controlled through the bar and lines that connect to your harness, which is worn around your midsection. The kite can be flown specific patterns to generate power, and can even be used to jump high in the air. And when we say jump, we really mean it. Professional kiteboarders can jump 50 or 60 feet high and can easily float for hundreds of feet when the conditions are right. That's nearly 10 seconds of air time!

Kite boarding is the fastest growing water sport in the world. The key to this sport is the Wind. This is what motivated us to do our analysis on Wind. 
Wind being the key element of kiteboarding, there are a lot of details that come into play for a safe and good ride. Wind direction and wind power are the two most important elements for kiteboarders. The wind direction to be on-shore or side on-shore and the power to create enough power and acceleration for kiting. Wind power is normally measured in MPH or Knots. A good kite boarding day starts at 15MPH. That being said, too much power is not safe. Meaning that smaller size kites are used for more powerful winds. Normally kiteboarders look at increments of wind to choose their kites. For a 15 - 20 MPH, a 12 meter kite does a great job. For stronger winds between 20 - 25 perhaps a 9 meter is good for an average weighted person. for over 25+ MPH depending on the skill level smaller kites should be used. Below is a good reference to learn more about winds and kiting:
http://www.gokite.com.au/resources/education/understanding-the-wind/

The purpose of this analysis is to find the best windy days that you can travel to Northern Yucutan for your kiting vacation. 

Happy Kiting!

# Data
```{r data_setup, include=FALSE}
executionStart <- Sys.time()
source('WeatherTest.R')
# General variables:
stationID <- "IYUCATNT2"
loc <- getPWSLocation(stationID)

startDateStr <- "2012/01/01"
#startDateStr <- "2016/01/01"
endDateStr <- "2016/12/31"
#endDateStr <- "2016/01/31"

sustainedWindTh <- 2

```

## Data Sources

```{r location, include=FALSE}
# Helper vars
latStr <- loc[1,"lat"]
lonStr <- loc[1,"lon"]
```

Original source is the CINVESTAV weather station (Mexican research center), ID `r stationID`, located in Telchac Yucatan. Coordinates are latitude `r latStr` and longitude `r lonStr`.

```{r station_map, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center',fig.height=7, fig.width=7}
pmap <- getPWSMap(stationID)
print(pmap)
```

We gathered the data from the weather underground website (https://www.wunderground.com). For instance the following URL will provide a close to CSV format (Except for some html tags inserted) for the day of January 1st 2016:

https://www.wunderground.com/weatherstation/WXDailyHistory.asp?ID=IYUCATNT2&month=1&day=1&year=2016&format=1

The project can be run in online mode where it will pull the data from weather underground website (https://www.wunderground.com) or it can run in offline mode where the data is pulled from a local cache saved in csv. Offline mode is strongly recommended since the online access relies on weatherData library that we had to patch for a bug plus weather underground data becomes unavailable from time to time. Instructions will be provided in the appendix.

## Summary of the Data

```{r sample_date, include=FALSE}
# Helper vars
#sampleDate <- "January 15, 2016" #orig
sampleDate <- "April 18, 2016"
#sampleDate <- "March 20, 2016"
startYear <- year(startDateStr)
endYear <- year(endDateStr)
yearSpan <- 1 + endYear-startYear 

sampleData <- getPWSData(stationID, as.Date(sampleDate,"%B %d, %Y")) %>%
  select(Time,WindDirection,WindDirectionDegrees,WindSpeedMPH,WindSpeedGustMPH)

#TODO : use real start and end
rawDataInfo <- getRawData(stationID,startDateStr,endDateStr)
#rawDataInfo <- getRawData(stationID,"2012/01/01","2012/03/31")

```

We analyzed a total of `r yearSpan` years of data from `r startYear` to `r endYear`. The information was obtained from weather underground website giving a single web page summary per day. This is an extract from `r sampleDate`:

```{r sample_data, echo=FALSE}
knitr::kable(head(sampleData))
```

There are many more columns related to pressure, temperature, dew point, etc. but for this analysis we only focused on the following:

_Time_ : The data we are dealing with is a time series. This is the timestamp at which the sample is taken.

_WindDirection_ : Cardinal direction where the wind is coming from. Not really used for analysis but just for display.

_WindDirectionDegrees_ : This is the wind direction in degrees. The cardinal directions map as follow: North is 0$^\circ$, East is 90$^\circ$, South is 180$^\circ$ and West is 270$^\circ$.

_WindSpeedMPH_ : Wind speed measured in miles per hour (mph).

_WindSpeedGustMPH_ : Wind gust measured in miles per hour (mph).

During the period of `r yearSpan` years a total of `r rawDataInfo$records` records were read from the web and `r rawDataInfo$badRecords` were missing from the server. This gives a total of `r nrow(rawDataInfo$data)` measurements to analyze.

This is the summary of the data from the raw data set:

```{r raw_data_summary, echo=FALSE}
knitr::kable(summary(rawDataInfo$data))
```

## Measurement Cleanup

We could easily spot there are negative values for the 3 columns of interest. Those are impossible values for those columns, further analysis showed that's the way the server reports the NA values. In case of wind direction there is also very big positive values greater than 360. When the wind speed is zero the server sometimes reports the direction as a negative value but when the direction reading is missing it reports it as a very high positive. The maximum numbers for wind speed and gust seem to be on a reasonable range so we consider them good readings.

Finally there are some entries in the data set that have duplicated Time values. They are not exactly duplicated readings since they could have other values in the remaining columns. It looks like sometimes some readings that were intended to happen minutes apart were recorded in the same timestamp. Instead of trying to guess the correct timestamp we simply deleted them, there were only `r sum(duplicated(rawDataInfo$data$Time))` entries in this situation plus future cleanup will minimize the effects of deleting them.

This is a summary of the data cleanup.

Condition                  | Action
---------------------------|--------------
WindDirectionDegrees < 0   | Convert to NA
WindDirectionDegrees > 360 | Convert to NA
WindSpeedMPH < 0           | Convert to NA
WindSpeedGustMPH < 0       | Convert to NA
duplicated(Time)           | Delete

Although converting to NA doesn’t sound like a good cleanup strategy it will make sense in the next step.

## Temporal Data Cleanup

The data is a time series which should be indexed by the Time column. The data set doesn’t have any information of the time zone which becomes important for future analysis. We had to force such information to the Time column setting the timezone to "America/Mexico_city"

The minimum difference between readings of the same day is 5 minutes but there are situations when the reading for the next 5 min is not taken or the period shifts. The following table shows the 5 most common intervals in the data set (in seconds):

```{r interval_info, echo=FALSE}
Intervals <- with(rawDataInfo$data,difftime(Time[-1],Time[-length(Time)]))
intFreq <- data.frame(head(sort(table(Intervals),decreasing=TRUE),5))
knitr::kable(intFreq)
#colnames(tmp) <- c("Interval","Frequency")
#head(sort(table(intervals),decreasing=TRUE),5)

```


In order to make the data set more manageable for future processing we decided to make each day evenly sampled at 5 minutes interval adding interpolated values in the case of missing timestamp.

Since the data set is a temporal series we converted the data to zoo objects in R and executed the following steps for interpolation for each day:

1. Create a new empty data set (zoo) with only a time series starting with the first timestamp of the day we want to interpolate, ending with the same timestamp as the original data set and equally spaced by 5 minutes.
2. Merge the new empty data set with the old original one for the date as a full outer join creating NA readings for the timestamps that didn’t exist.
3. Use the operation na.approx on the merged zoo object which will result in approximating the NA values using interpolation between neighboring readings.
4. Merge again the empty dataset with the merged data set as a natural join. This will eliminate any irregular reading taken outside the 5 min sampling rate.

Let’s take a look at an extract of samples around noon from `r sampleDate`:


```{r interpolation_example1, echo=FALSE}
pseudoDate <- floor_date(sampleData$Time[1],unit="day")
filteredSampleData <- sampleData %>%
  filter(Time>=pseudoDate+dhours(11.5)) %>%
  filter(Time<=pseudoDate+dhours(13.5))
sampleZoo <- convertPWSData2Zoo(filteredSampleData)
plot(sampleZoo$WindSpeedMPH,type="b", main=sprintf("Wind Speed for %s",sampleDate), sub="Extract", xlab="Time", ylab="Wind Speed (MPH)")
```

The next graph is the same period of time with the interpolated samples added:

```{r interpolation_example2, echo=FALSE}
intZoo <- interpolateZoo(sampleZoo)
plot(intZoo$WindSpeedMPH,type="b", main=sprintf("Wind Speed for %s",sampleDate), sub="Interpolated", xlab="Time", ylab="Wind Speed (MPH)")

```

```{r raw_data_cleanup, include=FALSE}

rm(rawDataInfo,sampleZoo,intZoo,Intervals,pseudoDate,intFreq,filteredSampleData)

```

# Analysis

## Whole Data Set Analysis

```{r whole_data_set, include=FALSE}
# This section needs to be completely silenced
df <- getCleanPWSDataRange(stationID,startDateStr,endDateStr) #Whole
#knitr::kable(df) #Dont print this it is for debug only
```

The first analysis done after cleaning the date was to get a windrose diagram to see the wind speed and direction distribution for the `r yearSpan` years we are analyzing. A windrose diagram is just a histogram in polar coordinates. It is divided by month since we are interested on finding the good season for kiting.

```{r wind_rose_whole, echo=FALSE, warning=FALSE, fig.align='center',fig.height=8, fig.width=8}
# There is a warning comming from this function
windRoseCleanData(df)

```

Visually we can observe that the months of August and October look like the weakest. The winter-spring months seem to have the highest winds overall. May seems to be a good solid month.

There are 2 dominant wind directions north-east and south-east. NE winds are stronger overall compared to the SE ones. This is good news since the NE direction creates a side-onshore direction excellent for kiting in the north shore.

## Daily Summary
```{r daily_summary, echo=FALSE}
daySum <- computeDailySummary(df,loc,sustainedWindTh)
```

The information from the wind rose is a good quick outlook of how to the winds distribute along the year but it doesn’t answer the question of how many good days for kiting a month has.

Instead we went for a more “visual” approach. Everyday is scanned to look for a period of at least `r sustainedWindTh` hours of sustained winds in the ranges of 15, 20 and 25 mph. The fact that each day was resampled at 5 min intervals greatly simplifies this analysis since it becomes a counting problem rather than calculating time differences.

Kiteboarding is only practice during daytime, we removed the measurements that were taken (or interpolated) at times when there was no sunlight before computing the daily summaries. The sunset and sunrise times are calculated for each day using the `sunriset` function from `maptools`.

This is a list of the computations performed using the column name in the final daily summary data frame:

_avgDlWindSpeedMPH, avgDlWindDirectionDegrees_ : This is the average wind speed and direction during the daylight. The averages are not relevant for the final report but they provided a way to do early estimation. 

_periodLength15, periodLength20, periodLength25_ : These are the most important measurements. We look for the amount of time the wind speed was equal or greater than 15, 20 and 25 mph respectively. A time range is only good if we have at least `r sustainedWindTh` hours of contiguous wind over the desired speed otherwise the time is not counted (becomes zero). If there are multiple periods going over the `r sustainedWindTh` hours threshold then they are added together. Lets use again the example of `r sampleDate`:

```{r windmeasurements, echo=FALSE}

# Doing the zoo of the whole thing:
sampleZoo <- convertPWSData2Zoo(sampleData)
sampleZoo <- interpolateZoo(sampleZoo)
plot(sampleZoo$WindSpeedMPH,type="l", main=sprintf("Wind Speed for %s",sampleDate), xlab="Time", ylab="Wind Speed (MPH)")

abline(h=15,lty="dotted")
abline(h=20,lty="dotted")
abline(h=25,lty="dotted")

rm(sampleZoo)
```

This one contains period of times where the wind speed is sustained for more than `r sustainedWindTh` hours being equal or greater than the three thresholds. Non zero values will be captured in the three of them.

_pseudoWindSpeed_ : We capture here the highest sustained speed above the predefined thresholds. In the previous graph for `r sampleDate` this field will have 25 since there is a period of time that the wind blows for more than `r sustainedWindTh` hours at 25 mph or more.

_avgDlWindSpeedMPHGt15, avgDlWindDirectionDegreesGt15_ : These are the average wind speed and direction of all the measurements greater than 15 mph. Only calculated when there was at least a period of `r sustainedWindTh` hours when the wind blows above 15 mph (periodLength15>0) otherwise they are NA. This measurements are useful for the arrow in the calendar plot.

### Calendar Plot for windy days

With this information we created a calendar plot where each day is classified into a no wind day, low wind, middle wind or high wind day based on the ranges of 15mph, 20mpg or 25mph and beyond. This is based again on the criteria of sustained wind for at least `r sustainedWindTh` hours.

Whenever there is a windy day (>15mph) then we also get an arrow indicating the average wind direction of the windy range, this information comes from columns _avgDlWindSpeedMPHGt15_ (size of arrow) and _avgDlWindDirectionDegreesGt15_ (direction). For this report only the last year is printed, refer to the appendix for the remaining years.

```{r calendar_last_year, echo=FALSE, warning=FALSE, fig.align='center',fig.height=8, fig.width=8}

targetDate <- year(endDateStr)
calendarDailySummary(daySum,targetDate)

```

## Monthly Report
```{r monthly_summary, include=FALSE}
monthSum  <- computeMontlySummary(daySum)

```

Finally we process the daily information to find out how many windy days we have had in the historic data per month. This is measured as a percentage.

The following overlapping bar charts were created as the final report:

```{r monthly_plot, echo=FALSE}
plt <- ggplotMontlySummary(monthSum,startDateStr,endDateStr)
print(plt)
```

# Conclusions
```{r, include=FALSE}
monthRankByWind <- monthSum[order(-monthSum$gteq15),]
monthRankByStr <- monthSum[order(-monthSum$gteq25),]

#monthRank$month[1]
#round(monthRank$gteq15[1]*100)

```

In the period from `r startYear` to `r endYear` the best month is `r monthRankByWind$month[1]` with `r round(monthRankByWind$gteq15[1]*100)`% of windy days and `r round(monthRankByWind$gteq20[1]*100)`% of windy days with at least 20mph speeds. This is followed by `r monthRankByWind$month[2]` with `r round(monthRankByWind$gteq15[2]*100)`% of windy days and `r monthRankByWind$month[3]` with `r round(monthRankByWind$gteq15[3]*100)`% of windy days.

The highest winds could typically be found in `r monthRankByStr$month[1]` with `r round(monthRankByStr$gteq25[1]*100)`% of windy days with speeds of 25mph and above.

It is a safe bet to take a medium (9m) and a large (12m) kites since most of the windy days are in the range of 15mph to less than 25mph.

# Appendix

## A. How to Run

This is the list of source files and directories needed to run, all of them need to be present **in the same directory**:

__WeatherTest.R__ : This is where most of the processing and plotting functions are implemented. It is included in the markdown documents.

__Report.Rmd__ : This report.

__Final_preso_wind.Rmd__ : Presentation.

__weatherc__ : A directo  ry containing all the cvs files with the daily information. It is organized in several subdirectories first the station ID, then the year and then the month.

To do the processing open the source file of this report and click on knit.

The library weatherData has been commented out from the code. This will make the code fail when the weather cache (directory weatherc) doesn’t exist:

Quitting from lines 67-82 (Report.Rmd) 
Error in getPWSData(stationID, as.Date(sampleDate, "%B %d, %Y")) : 
  could not find function “getDetailedWeather"

The current version from CRAN is old and it doesn’t read the weather data from the page correctly. The one from github is better but it has an issue related to the hidden <br> tags present in the page.

## B. Remaining calendar plots

_Note_ : No color on a day represents a missing record.

```{r calendars, echo=FALSE, warning=FALSE, fig.align='center'}

currYear <- targetDate-1

# Loop unrolling because the for puts the calendars next to each other
if (currYear >= year(startDateStr)) {
  calendarDailySummary(daySum,currYear)
  currYear <- currYear - 1
}
if (currYear >= year(startDateStr)) {
  calendarDailySummary(daySum,currYear)
  currYear <- currYear - 1
}
if (currYear >= year(startDateStr)) {
  calendarDailySummary(daySum,currYear)
  currYear <- currYear - 1
}
if (currYear >= year(startDateStr)) {
  calendarDailySummary(daySum,currYear)
  currYear <- currYear - 1
}

#calendarDailySummary(daySum,2014)

```

## C. Runtime

It took the following amount of time to generate this report:

```{r runtime, echo=FALSE}

# For regression compare against goldens
write.csv(df, "test.csv")
write.csv(daySum, "test2.csv")
write.csv(monthSum, "test3.csv")

totalRun <- Sys.time() - executionStart
totalRun
```