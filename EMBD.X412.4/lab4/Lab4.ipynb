{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explore MapReduce: Copy and paste these lines to see how to use Map and Reduce functions in Spark. Copy and paste the session output to submit for this Lab.\n",
    "\n",
    "```\n",
    ">>> from __future__ import print_function\n",
    ">>> import sys\n",
    ">>> from operator import add\n",
    ">>>\n",
    ">>> # Load the lab3-iot-gendata.txt file for processing as a Resilient Distributed Dataset (RDD)\n",
    ">>> textFile = spark.sparkContext.textFile(\"lab3-iot-gendata.txt\")\n",
    ">>> \n",
    ">>> # Output the histogram\n",
    ">>> counts = textFile.flatMap(lambda x: x.split(' ')) \\\n",
    "...   .map(lambda x: (x, 1)) \\\n",
    "...   .reduceByKey(add)\n",
    ">>> output = counts.collect()\n",
    ">>> for (word, count) in output:\n",
    "...    print(\"%s: %i\" % (word, count))\n",
    "...\n",
    ">>> # Quit the shell\n",
    ">>> quit()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77: 5\n",
      ": 101\n",
      "84: 1\n",
      "76: 3\n",
      "68: 1\n",
      "81: 5\n",
      "82: 7\n",
      "103: 2\n",
      "85: 4\n",
      "73: 4\n",
      "63: 2\n",
      "79: 3\n",
      "86: 2\n",
      "101: 1\n",
      "62: 2\n",
      "87: 1\n",
      "74: 3\n",
      "102: 1\n",
      "100: 1\n",
      "104: 2\n",
      "88: 1\n",
      "60: 1\n",
      "65: 4\n",
      "98: 2\n",
      "92: 2\n",
      "90: 6\n",
      "78: 2\n",
      "94: 1\n",
      "93: 1\n",
      "96: 6\n",
      "95: 2\n",
      "64: 3\n",
      "71: 3\n",
      "70: 2\n",
      "61: 2\n",
      "89: 3\n",
      "97: 1\n",
      "75: 2\n",
      "83: 2\n",
      "91: 1\n",
      "99: 2\n",
      "67: 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "from operator import add\n",
    "\n",
    "textFile = spark.sparkContext.textFile(\"lab3-iot-gendata.txt\")\n",
    "\n",
    "counts = textFile.flatMap(lambda x : x.split(' ')) \\\n",
    "    .map(lambda x: (x, 1)) \\\n",
    "    .reduceByKey(add)\n",
    "\n",
    "output = counts.collect()\n",
    "for (word, count) in output:\n",
    "    print(\"%s: %i\" % (word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explore Filter: Copy and paste these lines to see how to use Map, Filter, and Reduce functions in Spark. Copy and paste the session output to submit for this Lab.\n",
    "\n",
    "```\n",
    ">>> from __future__ import print_function\n",
    ">>> import sys\n",
    ">>> from operator import add\n",
    ">>>\n",
    ">>> textFile = spark.sparkContext.textFile(\"lab3-iot-gendata.txt\") \n",
    ">>> \n",
    ">>> # Output the filtered histogram \n",
    ">>> counts = textFile.flatMap(lambda x: x.split(' ')) \\\n",
    "... .filter(lambda x: x <= \"89\") \\\n",
    "... .map(lambda x: (x, 1)) \\\n",
    "... .reduceByKey(add)\n",
    ">>> output = counts.collect()\n",
    ">>> for (word, count) in output:\n",
    "...    print(\"%s: %i\" % (word, count))\n",
    "#####\n",
    "# NOTE 1: Take a screenshot/snapshot or copy and paste the session output to submit for this Lab.\n",
    "#####\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77: 5\n",
      ": 101\n",
      "84: 1\n",
      "76: 3\n",
      "68: 1\n",
      "81: 5\n",
      "82: 7\n",
      "103: 2\n",
      "85: 4\n",
      "73: 4\n",
      "63: 2\n",
      "79: 3\n",
      "86: 2\n",
      "101: 1\n",
      "62: 2\n",
      "87: 1\n",
      "74: 3\n",
      "102: 1\n",
      "100: 1\n",
      "104: 2\n",
      "88: 1\n",
      "60: 1\n",
      "65: 4\n",
      "78: 2\n",
      "64: 3\n",
      "71: 3\n",
      "70: 2\n",
      "61: 2\n",
      "89: 3\n",
      "75: 2\n",
      "83: 2\n",
      "67: 1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "from operator import add\n",
    "\n",
    "textFile = spark.sparkContext.textFile(\"lab3-iot-gendata.txt\") \n",
    "\n",
    "# Output the filtered histogram \n",
    "counts = textFile.flatMap(lambda x: x.split(' ')) \\\n",
    "    .filter(lambda x: x <= \"89\") \\\n",
    "    .map(lambda x: (x, 1)) \\\n",
    "    .reduceByKey(add)\n",
    "output = counts.collect()\n",
    "for (word, count) in output:\n",
    "    print(\"%s: %i\" % (word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b Fixing the issues with the example, filtering with number not lexicographically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77: 5\n",
      "84: 1\n",
      "76: 3\n",
      "68: 1\n",
      "81: 5\n",
      "82: 7\n",
      "85: 4\n",
      "73: 4\n",
      "63: 2\n",
      "79: 3\n",
      "86: 2\n",
      "62: 2\n",
      "87: 1\n",
      "74: 3\n",
      "88: 1\n",
      "60: 1\n",
      "65: 4\n",
      "78: 2\n",
      "64: 3\n",
      "71: 3\n",
      "70: 2\n",
      "61: 2\n",
      "89: 3\n",
      "75: 2\n",
      "83: 2\n",
      "67: 1\n"
     ]
    }
   ],
   "source": [
    "# Output the filtered histogram \n",
    "counts2 = textFile.flatMap(lambda x: x.split()) \\\n",
    "    .filter(lambda x: int(x) <= 89) \\\n",
    "    .map(lambda x: (x, 1)) \\\n",
    "    .reduceByKey(add)\n",
    "output2 = counts2.collect()\n",
    "for (word, count) in output2:\n",
    "    print(\"%s: %i\" % (word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Modify Step #2 with a compound Filter comparison to find a range instead of a threshold (HINT: Try using and/or).  Make sure to correct any bugs in the compound Filter so that the actual values in your output match the range of values that is expected from the modification.\n",
    "\n",
    "```\n",
    "#####\n",
    "# NOTE 2: Take a screenshot/snapshot or copy and paste the modified Python code\n",
    "#         you created along with the session output to submit for this Lab.\n",
    "#####\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I'll use a filter that changes a range from 80 to 89 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84: 1\n",
      "81: 5\n",
      "82: 7\n",
      "85: 4\n",
      "86: 2\n",
      "87: 1\n",
      "88: 1\n",
      "89: 3\n",
      "83: 2\n"
     ]
    }
   ],
   "source": [
    "counts3 = textFile.flatMap(lambda x: x.split()) \\\n",
    "    .filter(lambda x: (int(x) <= 89) and (int(x) >= 80) ) \\\n",
    "    .map(lambda x: (x, 1)) \\\n",
    "    .reduceByKey(add)\n",
    "output3 = counts3.collect()\n",
    "for (word, count) in output3:\n",
    "    print(\"%s: %i\" % (word, count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
