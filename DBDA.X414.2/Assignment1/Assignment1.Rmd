---
title: "ASSIGNMENT 1"
author: "Roque Arcudia"
date: "February 20, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


**1.What is machine learning? What is the difference between data mining and machine learning? (2 points)**

Machine learning is the area of computer science that designs algorithms to learn patterns from historical data. It is based on training the algorithm with an input training set typically using statistical approaches. The algorithm should be able to generalize.

Data mining is in charge of discovering patterns and finding structure in a large and unstructured data sets. Machine Learning could be used as a tool for data mining but it also involve the use of other tools and techniques as database systems, visualization tools, etc.

**2. What is supervised and unsupervised learning? Give examples and applications where each can be used (2 points)**

In supervised learning the input training set is labeled. The goal is to find or approximate a function that best describes the relationship between the inputs and the outputs (labels). Supervised learning can be further divided into classification if the output is a set of discrete values and regression if the output is a continuous value.

Some examples would be credit card fraud detection, spam detection and image recognition in case of classification. An example of regression would be predicting stock value based on historical data.

In unsupervised learning the training data is given without labels. The goal is to find the structure or distribution of the input data. The most common type of unsupervised algorithm is clustering where we try to group the training set according to similarities. For instance we can group customers by shopping habits.

**3.What is normalization and why do you perform? Explain with examples. What are the different techniques used? (2 points)**

Normalization is the process to convert columns in a dataset that were measured in different scales to a common scale usually between 0 and 1.

It is used because different machine learning algorithms may be sensitive to the scale of the features. For instance if we use the Euclidean distance in kNN algorithm, the feature that uses the bigger scale will have more weight on the decision to find the nearest neighbors if we don’t normalize data.

Lets take an example where we have two features to try to predict the damage of a building in an earthquake: one of them is magnitude of earthquake (Richter) and the other is the number of storeys in the building.

Let’s assume our training set has one point with a magnitude 2 and the number of storeys is 20 and another point with a magnitude of 7 and number of storeys is 25. If we are given a 3rd test point where the magnitude is 3.5 and the storeys are 24 and we calculate the Euclidean distance then the nearest point of the two mentioned will be the one with the magnitude 7 earthquake since there is only 1 floor difference and 3.5 magnitude difference compared to the other point with 1.5 magnitude and 4 floors of difference.

If we assume that the magnitude in the whole training set has a range from 1 to 8 and the number of storeys has a range from 1 to 50 and we normalize from 0 to 1 both features we will see that the magnitude difference is much more important than the floor difference in this case.

Some techniques used (from lecture2b) are:

* Min and max:

$$v' = \frac{v-min_A}{max_A-min_A}(newmax_A-newmin_A) +newmin_A$$

* Z-score:
$$v' = \frac{v-mean_A}{stdev_A}$$

* Decimal scaling
$$v' = \frac{v}{10^j}$$
Where $j$ is the smallest integer such that $Max(|v'|)<1$

**4.What does K stand in K-nearest neighbor algorithm? How do you determine the optimal value of K. Take Wisconsin cancer data (provided), determine the optimal
value of K. Plot misclassification error for test as well as training data. ( 4 points)**

The parameter *k* is the number of nearest neighbors to be found by the algorithm given an input test point. The majority class label will be assigned to the test point.

```{r data_setup, include=FALSE}
source('KNN.r')
```

The parameter is typically chosen to be an odd number to avoid a tie. As a rule of thumb we can pick *k* to be the square root of the number of elements in the training set:

```{r k_size}
k_thumb <- sqrt(nrow(wbcd_train))
k_thumb
```

Trying different values of *k*:

```{r k_test}
k_test <- seq(1,k_thumb*2,2)
k_test
```

Calculating the misclassification using the testing set:

```{r k_mis_test, include=FALSE}
err_rate_test <- vector()
for(i in 1:length(k_test)){
  wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
                      cl = wbcd_train_labels, k=k_test[i])
  #CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq=FALSE)
  
  acc_test <- sum(wbcd_test_pred == wbcd_test_labels)/length(wbcd_test_labels)
  #print(acc_test)
  err_rate_test[i] <- 1-acc_test
}
err_rate_test

```

```{r k_mis_test_nl}

err_rate_test <- sapply(k_test,function(x){
  wbcd_test_pred <- knn(train = wbcd_train, test = wbcd_test,
                      cl = wbcd_train_labels, k=x)
  1 - sum(wbcd_test_pred == wbcd_test_labels)/length(wbcd_test_labels)
})

err_rate_test
```

Plotting the value of k with the associated misclassification rate in the testing set:
```{r k_mis_test_plot}
plot(k_test,err_rate_test,type="b",
     main="Misclassification error for testing set",
     xlab="k",ylab="Misclassification")
```

This plot shows that the value of 21 is a good choice.

Calculating the misclassification using the training set:

```{r k_mis_train, include=FALSE}
err_rate_train <- vector()
for(i in 1:length(k_test)){
  wbcd_train_pred <- knn(train = wbcd_train, test = wbcd_train,
                      cl = wbcd_train_labels, k=k_test[i])
  #CrossTable(x = wbcd_test_labels, y = wbcd_test_pred, prop.chisq=FALSE)
  
  acc_test <- sum(wbcd_train_pred == wbcd_train_labels)/length(wbcd_train_labels)
  #print(acc_test)
  err_rate_train[i] <- 1-acc_test
}
err_rate_train

```

```{r k_mis_train_nl}

err_rate_train <- sapply(k_test,function(x){
  wbcd_train_pred <- knn(train = wbcd_train, test = wbcd_train,
                      cl = wbcd_train_labels, k=x)
  1 - sum(wbcd_train_pred == wbcd_train_labels)/length(wbcd_train_labels)
})

err_rate_train
```

Plotting the value of k with the associated misclassification rate in the training set:
```{r k_mis_train_plot}
plot(k_test,err_rate_train,type="b",
     main="Misclassification error for training set",
     xlab="k",ylab="Misclassification")
```

Although in this case it looks like the smaller the better picking those values may create a generalization problem. 21 still looks as a good value before the error goes high peaking around 31.
